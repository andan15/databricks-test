{"cells":[{"cell_type":"code","source":["import numpy\nimport math\nimport time\nimport threading\nfrom datetime import date, datetime\nfrom numpy.linalg import norm\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.mllib.recommendation import ALS, Rating\nfrom scipy.spatial.distance import chebyshev, cosine\nfrom scipy.stats import entropy\nimport json\n\n\n\n\n\n# =====================================================================================================================\n# = ALS\n# =====================================================================================================================\n\n\ndef getALSCache(conf, s3Data):\n\n    hyperparams = conf['hyperparams']['als']\n    curTime = int(time.time() * 1000)\n    rangeInMilliseconds = hyperparams['minDays'] * 24 * 3600 * 1000\n\n    def decay(ts):\n        # 1 lineary going down to decayMin at minDays\n        return max((1 - (1.0 - hyperparams['decayMin']) * float(curTime - int(ts)) / rangeInMilliseconds),\n                   hyperparams['decayMin'])\n\n    def createRating(row):\n        viewed = map(lambda r: (r.productId, decay(r.updated)), row.products)\n        #print row\n        return [Rating(row.userId, val[0], val[1]) for val in viewed]\n\n    ratings = s3Data['viewing']['rdd'].flatMap(lambda r: createRating(r))\n    #for x in ratings.collect():\n    #  print x\n    alsModel = ALS.trainImplicit(ratings,\n            hyperparams['rank'],\n            hyperparams['numIterations'],\n            alpha=hyperparams['alpha'],\n            lambda_=hyperparams['lambda'])\n\n    prodsDictReversedBroadcast = sc.broadcast(s3Data['prods']['dictReversed']) # { 0: 'guid-series-1', 1: 'guid-movie-2' }\n    prodFeatures = alsModel.productFeatures().map(lambda r: (prodsDictReversedBroadcast.value[r[0]], list(r[1])))  # => ('guid-series-1, [1..rank])\n    prodsDictReversedBroadcast.unpersist()\n\n\n    # Inverse the unique id process, this is expensive - but no broadcasts\n    joined = alsModel.userFeatures().leftOuterJoin(s3Data['users']['rdd'])\n    userFeatures = joined.map(lambda r: (r[1][1], list(r[1][0])))\n\n    return {\n        'prods': prodFeatures,\n        'users': userFeatures\n    }\n\n# =====================================================================================================================\n# = Ranking\n# ======================================================================================================================\n\n\ndef distance(mainVec, relVec, weights):\n    mainVecAbs = map(abs, mainVec[1])\n    relVecAbs = map(abs, relVec[1])\n    distances = [\n        weights['cosine'] * cosine(mainVec[1], relVec[1]),\n        weights['eucl'] * math.tanh(numpy.linalg.norm(numpy.array(mainVec[1]) - numpy.array(relVec[1]))),\n        weights['chebychev'] * math.tanh(chebyshev(mainVec[1], relVec[1])),\n        weights['jsdistance'] * math.tanh(JensenShanonDistance(mainVecAbs, relVecAbs))\n    ]\n    return sum(distances) / float(len(distances))\n\n\ndef rank(mainVec, features=None, similarity_weights=None, available_products=None, limit=None):\n    prods = features.value\n    available_prods = available_products.value\n\n    prods_to_rank = filter(lambda prod: prod[0] in available_prods, prods)\n    rankedProds = sorted(prods_to_rank, key=lambda r: distance(mainVec, r, similarity_weights))\n\n    ##for prod in rankedProds[:2]: print(prod[1])\n\n    return [prod[0]+\"_\"+str(distance(mainVec, prod, similarity_weights)) for prod in rankedProds[:limit]]\n\n\n# =====================================================================================================================\n# = Saving\n# =====================================================================================================================\ndef saveToS3(conf, rankedLists, s3_path=None, suffix='', folder = ''):\n\n    print 'save partition'\n    print folder\n    rankedLists.repartition(1).saveAsTextFile('dbfs:/antonina/output/cf/'+folder + '/')\n    \n    \ndef markCompleted(s3Folder, conf=None):\n    name_store = s3Folder + '/' + conf['successFile']\n    print name_store\n    #dbutils.fs.put(name_store, findReplaceDate('%Y-%m-%d'))\n# =====================================================================================================================\n# = Miscellaneous functions\n# =====================================================================================================================\n\n\ndef is_sunday_today():\n    return datetime.today().weekday() == 6\n\n\ndef findReplaceDate(string):\n    return date.today().strftime(string)\n\n\ndef JensenShanonDistance(P, Q):\n    \"\"\"\n    An implementation of Jensen-Shanon divergence, properties being symmetric and finite.\n    \"\"\"\n    Pnonzero = [val if val > 0.001 else 0.00001 for val in P]  # Implementation caveat\n    Qnonzero = [val if val > 0.001 else 0.00001 for val in Q]\n    Pnorm = numpy.array(Pnonzero) / norm(numpy.array(Pnonzero), ord=1)\n    Qnorm = numpy.array(Qnonzero) / norm(numpy.array(Qnonzero), ord=1)\n    Mtmp = 0.5 * (Pnorm + Qnorm)\n    M = numpy.array([val if val > 0.001 else 0.00001 for val in Mtmp])\n    return math.sqrt(0.5 * (entropy(Pnorm, M) + entropy(Qnorm, M)))\n\n\n#######################################\n# Calculate ALS and Save data to S3\n#######################################\n\n\ndef rank_and_save_als_data(conf, features=None, products_available=None, suffix=None, folder_name = ''):\n    product_features_broadcast = sc.broadcast(features['prods'].collect())\n    available_prods_broadcast = sc.broadcast(products_available)\n\n    def rankProds(vec):\n        products = rank(vec,\n            features = product_features_broadcast,\n            similarity_weights = conf['hyperparams']['similarityWeights'],\n            available_products = available_prods_broadcast,\n            limit = conf['numberRecommended'])\n        return {'guid': vec[0], 'prods': products}\n\n    def generate_similarities(features):\n         product_similarities = features.filter(lambda prod: prod[0] in available_prods_broadcast.value).map(rankProds)\n         saveToS3(conf, product_similarities, s3_path=conf['write']['prods'], folder=folder_name+\"/similarities\")\n    def generate_recommendations(features):\n        if conf['recommendForUsers'] and (is_sunday_today() or conf['forceUserRecommendations']):\n            user_recommendations = features.map(rankProds)\n            saveToS3(conf, user_recommendations, s3_path=conf['write']['users'], suffix='/' + findReplaceDate('%Y-%m-%d') + suffix, folder = folder_name+\"/recommendations\")\n\n    generate_similarities(features['prods'])\n    generate_recommendations(features['users'])\n\n\ndef precalculate_als_data(conf, cleaned):\n    return {\n        's3': cleaned,\n        'ensemble': {\n            'als': getALSCache(conf, cleaned)\n            }\n        }\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":2}],"metadata":{"name":"als","notebookId":244},"nbformat":4,"nbformat_minor":0}